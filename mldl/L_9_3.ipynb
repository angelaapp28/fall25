{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L_9_3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"t0-VXSCM7avd","colab_type":"text"},"source":["# L-9-3: Inverse Classroom: Itâ€™s not working! Help!\n","\n","These exercises will give you some debugging experience on problems typically found when doing machine learning in practice.\n","\n","**Outline**\n","\n","0. General Set-up\n","1. Debugging A Bad Training Set-up\n","2. Image Segmentation with DICE Loss\n","3. Fixing the Data-Processing Pipeline\n","4. Test Performance is Too Good!"]},{"cell_type":"markdown","metadata":{"id":"3secgg798917","colab_type":"text"},"source":["## 0. General Set-up\n","\n","Here we provide general code set-up: package requirements, train-loaders, etc."]},{"cell_type":"code","metadata":{"id":"8ocl9Mfl8LH6","colab_type":"code","colab":{}},"source":["## Some general imports we may need:\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.utils.data\n","import matplotlib.pyplot as plt\n","import time\n","import struct"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uG5SflgE9eVz","colab_type":"text"},"source":["Make sure GPU is enabled: In Colab, at the top, \n","\n","click `Runtime` -> `Change runtime type` -> `Hardware Accelerator` -> `GPU`"]},{"cell_type":"code","metadata":{"id":"rFFtp9BmLxo9","colab_type":"code","colab":{}},"source":["gpu_boole = torch.cuda.is_available()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2bNXCy0voYj8","colab_type":"text"},"source":["##3. Fixing the Data-Processing Pipeline\n","\n","* Like in L-9-1, you are given a training loop for MNIST.\n","* There is a runtime error! How do you fix it?\n","* As it turns out, there are other errors too, having to do with data-processing.\n","* **Deliverables:** \n","    * Fix all runtime error(s).\n","    * Continue debugging until you achieve 90% or greater test accuracy in 10 epochs of training or less.\n","    * Describe the fixes you made."]},{"cell_type":"markdown","metadata":{"id":"vuXwJlDJrfot","colab_type":"text"},"source":["**Defining the model and optimizer:**\n","We define the model and optimizer here."]},{"cell_type":"code","metadata":{"id":"v1Zpa5BpocMw","colab_type":"code","colab":{}},"source":["## Defining the model:\n","class Net(nn.Module):\n","  def __init__(self, input_size, width, num_classes):\n","    super(Net, self).__init__()\n","\n","    ##feedfoward layers:\n","    self.ff1 = nn.Linear(input_size, width) #input\n","\n","    self.ff2 = nn.Linear(width, width) #hidden layers\n","    self.ff3 = nn.Linear(width, width)\n","\n","    self.ff_out = nn.Linear(width, num_classes) #logit layer     \n","\n","    ##activations:\n","    self.relu = nn.ReLU()\n","                \n","  def forward(self, input_data):\n","    out = self.relu(self.ff1(input_data)) \n","    out = self.relu(self.ff2(out)) \n","    out = self.relu(self.ff3(out))\n","    out = self.ff_out(out)\n","    return out #returns class probabilities for each image\n","\n","net = Net(input_size = 784, width = 500, num_classes = 10)\n","if gpu_boole:\n","  net = net.cuda()\n","\n","optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n","loss_metric = nn.CrossEntropyLoss()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZGhQTKQslTF","colab_type":"text"},"source":["**Data-loading:** In L-9-1, we made use of the `torchvision` package for data-loading and preprocessing. We abstracted away some preprocessing steps. Here, we are giving a more granular implementation that you may have to adjust in various ways. This is more akin to what you will see in practice with other datasets.\n"]},{"cell_type":"code","metadata":{"id":"aJEKRd5os_0D","colab_type":"code","colab":{}},"source":["#Downloading and unzipping MNIST data files:\n","!curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","!curl -O http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","!curl -O http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","!curl -O http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","!gunzip t*-ubyte.gz -f"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hCRWPxuvx0r","colab_type":"code","colab":{}},"source":["##Loading files into numpy arrays:\n","def read_idx(filename, boole=0):\n","    with open(filename, 'rb') as f:\n","        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n","        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n","        if boole:\n","          return np.fromstring(f.read(), dtype=np.uint8).reshape(shape).astype(np.float32)*10     \n","        else:\n","          return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n","\n","xtrain = read_idx('train-images-idx3-ubyte', 1)\n","xtest = read_idx('t10k-images-idx3-ubyte', 1)\n","ytrain = read_idx('train-labels-idx1-ubyte')\n","ytest = read_idx('t10k-labels-idx1-ubyte')\n","\n","np.random.shuffle(xtrain); np.random.shuffle(ytrain);\n","\n","xtrain = torch.Tensor(xtrain)\n","ytrain = torch.Tensor(ytrain)\n","ytrain = ytrain.reshape([-1,1])\n","xtest = torch.Tensor(xtest)\n","ytest = torch.Tensor(ytest)\n","ytest = ytest.reshape([-1,1])\n","\n","## data_loaders:\n","train = torch.utils.data.TensorDataset(xtrain, ytrain)\n","test = torch.utils.data.TensorDataset(xtest, ytest)\n","\n","train_loader = torch.utils.data.DataLoader(train, batch_size=128)\n","test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"790pcdr8zVcq","colab_type":"text"},"source":["**Defining training and test loss and accuracy functions:** These functions will be useful in our training loop to view are training and test loss/accuracy at each epoch."]},{"cell_type":"code","metadata":{"id":"HBb0OgrozOz4","colab_type":"code","colab":{}},"source":["def train_eval(verbose = 1):\n","    correct = 0\n","    total = 0\n","    loss_sum = 0\n","    for images, labels in train_loader:\n","        if gpu_boole:\n","            images, labels = images.cuda(), labels.cuda()\n","        images = images.view(-1, 28*28)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted.float() == labels.float()).sum()\n","\n","        loss_sum += loss_metric(outputs,labels)\n","        \n","    if verbose:\n","        print('Train accuracy: %f %%' % (100 * correct / total))\n","        print('Train loss: %f' % (loss_sum.cpu().data.numpy().item() / total))\n","\n","    return 100.0 * correct / total, loss_sum.cpu().data.numpy().item() / total\n","    \n","def test_eval(verbose = 1):\n","    correct = 0\n","    total = 0\n","    loss_sum = 0\n","    for images, labels in test_loader:\n","        if gpu_boole:\n","            images, labels = images.cuda(), labels.cuda()\n","        images = images.view(-1, 28*28)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted.float() == labels.float()).sum()\n","\n","        loss_sum += loss_metric(outputs,labels)\n","\n","    if verbose:\n","        print('Test accuracy: %f %%' % (100 * correct / total))\n","        print('Test loss: %f' % (loss_sum.cpu().data.numpy().item() / total))\n","\n","    return 100.0 * correct / total, loss_sum.cpu().data.numpy().item() / total"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KOJCQFm7zoCa","colab_type":"text"},"source":["**Traning loop:** here, we give the training loop. A number of epochs is set. Loss is recorded and plotted at the end.\n","\n","**IMPORTANT NOTE:** For re-running this code cell, if you encounter nan loss, you will need to reinstantiate your model and optimizer by re-running the \"Defining the model and optimizer:\" code cell above."]},{"cell_type":"code","metadata":{"id":"IGqGSQt2zeQ4","colab_type":"code","colab":{}},"source":["#re-initializing network weights:\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","        torch.nn.init.xavier_uniform(m.weight.data)\n","\n","weights_init(net)\n","\n","#number of epochs to train for:\n","epochs = 10\n","\n","#defining batch train loss recording arrays for later visualization/plotting:\n","loss_batch_store = []\n","\n","print(\"Starting Training\")\n","#training loop:\n","for epoch in range(epochs):\n","  time1 = time.time() #timekeeping\n","\n","  for i, (x,y) in enumerate(train_loader):\n","\n","    if gpu_boole:\n","      x = x.cuda()\n","      y = y.cuda()\n","\n","    #loss calculation and gradient update:\n","\n","    if i > 0 or epoch > 0:\n","      optimizer.zero_grad()\n","    outputs = net.forward(x)\n","    loss = loss_metric(outputs,y)\n","    loss.backward()\n","\n","    if i > 0 or epoch > 0:\n","      loss_batch_store.append(loss.cpu().data.numpy().item())\n","                  \n","    ##performing update:\n","    optimizer.step()\n","\n","  print(\"Epoch\",epoch+1,':')\n","  train_perc, train_loss = train_eval()\n","  test_perc, test_loss = test_eval()\n","\n","  time2 = time.time() #timekeeping\n","  print('Elapsed time for epoch:',time2 - time1,'s')\n","  print('ETA of completion:',(time2 - time1)*(epochs - epoch - 1)/60,'minutes')\n","  print()\n","\n","## Plotting batch-wise train loss curve:\n","plt.plot(loss_batch_store, '-o', label = 'train_loss', color = 'blue')\n","plt.xlabel('Minibatch Number')\n","plt.ylabel('Sample-wise Loss At Last minibatch')\n","plt.legend()\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LWdY3Xer2qTi","colab_type":"text"},"source":["**Debugging outline and hints:**\n","*   For an easier time, follow these hints:\n","1. First, you should get a reshaping error. This can be fixed in the training loop block.\n","2. Second, you should get a casting error. Try modifying *y* such that it is the correct data type. It is easiest to do this in the Data-loading block.\n","3. Third, you should get an error in your loss function. Go to the Data-loading block, are the shapes of your *y* tensors correct?\n","4. Fourth, in the Data-loading block, check the min and max values of your *x* tensors. Do they look correct?\n","5. Fifth, in the Data-loading block, check that your data-label mapping is correct.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HjXnCBCzqJY6","colab_type":"text"},"source":["**Describe your debugging process.**\n","\n","1. What errors/issues did you identify and resolve?\n","\n","[Your text here]\n","\n","2. What was your process for debugging? Describe the order of steps you took, debugging deadends you ran into, etc. There isn't necessarily a correct answer here, we just want to see an overview of what you tried and corrected for.\n","\n","[Your text here]"]},{"cell_type":"markdown","metadata":{"id":"FqbC5MEB2o-e","colab_type":"text"},"source":[""]}]}