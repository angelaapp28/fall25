{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelaapp28/fall25/blob/main/DeepLearning_Fall2025_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv1rSSHpWjHk"
      },
      "source": [
        "\n",
        "# Deep Learning Homework 6\n",
        "\n",
        "This code is provided for Deep Learning class (601.482/682) Homework 6. For ease of implementation, we recommend working entire in Google Colaboratory.\n",
        "\n",
        "@Copyright Hao Ding, Cong Gao, the Johns Hopkins University, hding15@jhu.edu, cgao11@jhu.edu.\n",
        "\n",
        "Modifications made by Hongtao Wu, Suzanna Sia, Hao Ding, Keith Harrigian, and Yiqing Shen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-_pErnekg0b"
      },
      "source": [
        "# Problem 1: Segmentation Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCSZrtRt3IEr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "import numpy as np                # Numpy for array manipulation for ease of access\n",
        "import torch                      # Pytorch for array manipulation on the GPU and nice deep learning functions\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "# Image import and display libraries                       # OpenCV for image processing\n",
        "import matplotlib.pyplot as plt   # Plotting functions\n",
        "%matplotlib inline\n",
        "\n",
        "# Image processing libraries for image feature extractor\n",
        "from scipy.stats import kurtosis, skew\n",
        "from scipy.ndimage.filters import generic_filter\n",
        "from skimage.filters import laplace, gabor\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "# A few more tools\n",
        "from sklearn import svm           # SVM classifier library\n",
        "import os                         # Navigate through directories\n",
        "import csv                        # Read in a CSV file\n",
        "import time                       # Timing function\n",
        "import pickle                     # Saving and loading variables\n",
        "\n",
        "# Mount Google Drive folder as a local folder\n",
        "# Note: This mounts your entire drive, not the current folder\n",
        "from google.colab import drive\n",
        "drive.mount('/mydrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIfpBYhPCTc3"
      },
      "outputs": [],
      "source": [
        "#TODO replace the path with your path in drive\n",
        "#This usually takes 5 minutes to run\n",
        "!cp /mydrive/MyDrive/SegSTRONGC/SegSTRONGC_MLDL/SegSTRONGC_MLDL.zip ./\n",
        "# Uncomment if you feel necesarry\n",
        "# !rm -r SegSTRONGC_MLDL\n",
        "# !rm -r __MACOSX/\n",
        "!unzip SegSTRONGC_MLDL.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAL5Q4FBBQT-"
      },
      "source": [
        "### Hyperparameters\n",
        "\n",
        "We provide an initial hyper parameter, feel free to change according to your need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqHXYpiGiHtW"
      },
      "outputs": [],
      "source": [
        "#TODO tune your own parameters\n",
        "batch_size = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "use_gpu = False\n",
        "if torch.cuda.is_available(): #use gpu if available\n",
        "  use_gpu = True\n",
        "  print(\"using cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIZwwPkYXA-6"
      },
      "source": [
        "### Data Loaders\n",
        "\n",
        "We have provided you with some preprocessing code for the images but you should feel free to modify the class however you please to support your training schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5_qirSz5INa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import os.path as osp\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "class SegSTRONGC(data.Dataset):\n",
        "    def __init__(self, root_folder: str, set_indices: list, subset_indices: list, split: str = 'train', domains: list = ['regular'], image_transforms = None, gt_transforms = None):\n",
        "        '''\n",
        "            reference dataset loading for SegSTRONGC\n",
        "            root_folder: the root_folder of the SegSTRONGC dataset\n",
        "            set_indices: is the indices for sets to be used\n",
        "            subset_indices: is the indices for the subsets to be used\n",
        "            split: 'train', 'val' or 'test'\n",
        "            domain: the image domains to be loaded.\n",
        "            image_transforms: any transforms to perform, can add augmentations here.\n",
        "            gt_transforms: list of bool. Indicates whether image_transforms should also be appleid to gt.\n",
        "        '''\n",
        "        self.split = split\n",
        "        self.root_folder = root_folder\n",
        "        self.set_indices = set_indices\n",
        "        self.subset_indices = subset_indices\n",
        "        self.domains = domains\n",
        "        self.image_transforms = image_transforms\n",
        "        self.gt_transforms = gt_transforms\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.gt_paths = []\n",
        "\n",
        "        for set_idx, s in enumerate(self.set_indices):\n",
        "            for ss in self.subset_indices[set_idx]:\n",
        "                set_folder = osp.join(self.root_folder, self.split + '/' + str(s) + '/' + str(ss))\n",
        "                gt_folder = osp.join(set_folder, 'ground_truth')\n",
        "\n",
        "                for d in self.domains:\n",
        "                    image_folder = osp.join(set_folder, d)\n",
        "                    for i in range(300):\n",
        "                        image_name = str(i) + \".jpg\"\n",
        "                        gt_name = str(i) + \".png\"\n",
        "                        self.image_paths.append(osp.join(image_folder, 'left/' + image_name))\n",
        "                        self.gt_paths.append(osp.join(gt_folder, 'left/' + gt_name))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        image = np.array(Image.open(self.image_paths[idx])).astype(np.float32) / 255\n",
        "        gt = (np.array(Image.open(self.gt_paths[idx])) / 255).astype(np.int64)\n",
        "        # Apply transformation to image and ground truth\n",
        "        if self.image_transforms is not None and self.gt_transforms is not None:\n",
        "            image = self.image_transforms(image)\n",
        "            gt = self.gt_transforms(gt)\n",
        "        else:\n",
        "            image = T.ToTensor()(image)\n",
        "            gt = T.ToTensor()(gt)\n",
        "\n",
        "        return image, gt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B1LjdxNBVu3"
      },
      "source": [
        "## Model Architecture\n",
        "\n",
        "Finish building the U-net architecture below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8qbYbMv48_j"
      },
      "outputs": [],
      "source": [
        "\n",
        "def add_conv_stage(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, useBN=False):\n",
        "  if useBN:\n",
        "    return nn.Sequential(\n",
        "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.BatchNorm2d(dim_out),\n",
        "      nn.LeakyReLU(0.1),\n",
        "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.BatchNorm2d(dim_out),\n",
        "      nn.LeakyReLU(0.1)\n",
        "    )\n",
        "  else:\n",
        "    return nn.Sequential(\n",
        "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "\n",
        "def add_merge_stage(ch_coarse, ch_fine, in_coarse, in_fine, upsample):\n",
        "  conv = nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
        "  torch.cat(conv, in_fine)\n",
        "\n",
        "  return nn.Sequential(\n",
        "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
        "  )\n",
        "  upsample(in_coarse)\n",
        "\n",
        "def upsample(ch_coarse, ch_fine):\n",
        "  return nn.Sequential(\n",
        "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n",
        "    nn.ReLU()\n",
        "  )\n",
        "\n",
        "class unet(nn.Module):\n",
        "  def __init__(self, useBN=False):\n",
        "    super(unet, self).__init__()\n",
        "    # Downgrade stages\n",
        "    self.conv1   = add_conv_stage(3, 32, useBN=useBN)\n",
        "    self.conv2   = add_conv_stage(32, 64, useBN=useBN)\n",
        "    self.conv3   = add_conv_stage(64, 128, useBN=useBN)\n",
        "    self.conv4   = add_conv_stage(128, 256, useBN=useBN)\n",
        "    self.conv5   = add_conv_stage(256, 512, useBN=useBN)\n",
        "    # Upgrade stages\n",
        "    self.conv4m = add_conv_stage(512, 256, useBN=useBN)\n",
        "    self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n",
        "    self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n",
        "    self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n",
        "    # Maxpool\n",
        "    self.max_pool = nn.MaxPool2d(2)\n",
        "    # Upsample layers\n",
        "    self.upsample54 = upsample(512, 256)\n",
        "    self.upsample43 = upsample(256, 128)\n",
        "    self.upsample32 = upsample(128,  64)\n",
        "    self.upsample21 = upsample(64 ,  32)\n",
        "\n",
        "    ## TODO Design your last layer & activations\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    #TODO implement forward function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2-ixeAYCcCk"
      },
      "source": [
        "Here defines trainning functions, diceloss functions and dice evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jarbTWEG6zH7"
      },
      "outputs": [],
      "source": [
        "def trainning(model, trainning_dataloader, validation_dataloader, num_epochs, criterion, optimizer, filename):\n",
        "    if use_gpu:\n",
        "      model.cuda()\n",
        "    lr_changed = False\n",
        "    trainning_losses = []\n",
        "    validation_losses = []\n",
        "    total_training_loss = 0\n",
        "    total_val_loss = 0\n",
        "    total_training_iteration = 0\n",
        "    total_val_iteration = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        i = 0\n",
        "        model.train()\n",
        "        for data in trainning_dataloader:\n",
        "          img,y = data\n",
        "          if use_gpu:\n",
        "            img = img.cuda()\n",
        "            y = y.cuda()\n",
        "          out = model(img)\n",
        "          model.zero_grad()\n",
        "          loss = criterion(out, y)\n",
        "          total_training_loss += loss.item()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          i = i+1\n",
        "          total_training_iteration += 1\n",
        "          if total_training_iteration % 100 == 99:\n",
        "            trainning_losses.append(total_training_loss / total_training_iteration)\n",
        "        if epoch % 5 == 4:\n",
        "            print(\"learning_rate decayed\")\n",
        "            for param_group in optimizer.param_groups:\n",
        "              param_group['lr'] *= 0.1\n",
        "        model.eval()\n",
        "        for data in validation_dataloader:\n",
        "          img,y = data\n",
        "          if use_gpu:\n",
        "            img = img.cuda()\n",
        "            y = y.cuda()\n",
        "          out = model(img)\n",
        "          model.zero_grad()\n",
        "          loss = criterion(out, y)\n",
        "          total_val_loss += loss.item()\n",
        "          total_val_iteration += 1\n",
        "          if total_val_iteration % 100 == 99:\n",
        "            validation_losses.append(total_val_loss / total_val_iteration)\n",
        "        print(\"epoch:\",epoch,\"training_loss:\",total_training_loss / total_training_iteration, \"validation_loss:\",total_val_loss / total_val_iteration)\n",
        "        torch.save(model.state_dict(), filename)\n",
        "    plt.plot(trainning_losses)\n",
        "    plt.show()\n",
        "    plt.plot(validation_losses)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBampHkAkoPD"
      },
      "source": [
        "### DICE Score and DICE Loss\n",
        "\n",
        "Finish implementing the DICE score function below and then write a Dice Loss function that you can use to update your model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaOSEue9Zr3f"
      },
      "outputs": [],
      "source": [
        "def DICE(model, test_dataloader, smooth=1e-10):\n",
        "    dice = []\n",
        "    model.eval()\n",
        "    for data in test_dataloader:\n",
        "        img, target = data\n",
        "        if use_gpu:\n",
        "            img = img.cuda()\n",
        "            target = target.cuda()\n",
        "        predict = model(img) > 0.5\n",
        "        num = 2 * (predict * target).sum()\n",
        "        denum = predict.sum() + target.sum()\n",
        "        dice.append(((num + smooth) / (denum + smooth)).item())\n",
        "    m_dice = np.mean(dice)\n",
        "    return m_dice\n",
        "\n",
        "def DICELoss(scores, target):\n",
        "    # TODO complete dice loss to calculate dice of the segmented tool according to the dice score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pQRfgNBDVVu"
      },
      "source": [
        "define transforms and vanilla dataset for trainning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWj-0z-cUi1J"
      },
      "outputs": [],
      "source": [
        "root_folder = \"./SegSTRONGC_MLDL\" #TODO replace with your own path\n",
        "size = (272, 480)\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "train_set_indices = [3, 4, 5, 7, 8]\n",
        "train_subset_indices = [[0, 2], [0, 1, 2], [0, 2], [0, 1], [1, 2]]\n",
        "\n",
        "train_image_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "train_gt_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST)\n",
        "])\n",
        "segmentation_trainning_dataset = SegSTRONGC(\n",
        "    root_folder = root_folder,\n",
        "    set_indices = train_set_indices,\n",
        "    subset_indices = train_subset_indices,\n",
        "    split = 'train',\n",
        "    domains = ['regular'],\n",
        "    image_transforms = train_image_transforms,\n",
        "    gt_transforms = train_gt_transforms)\n",
        "segmentation_trainning_dataloader = DataLoader(segmentation_trainning_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_set_indices = [1]\n",
        "val_subset_indices = [[0]]\n",
        "\n",
        "val_image_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "val_gt_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST)\n",
        "])\n",
        "segmentation_validation_dataset = SegSTRONGC(\n",
        "    root_folder = root_folder,\n",
        "    set_indices = val_set_indices,\n",
        "    subset_indices = val_subset_indices,\n",
        "    split = 'val',\n",
        "    domains = ['regular'],\n",
        "    image_transforms = val_image_transforms,\n",
        "    gt_transforms = val_gt_transforms)\n",
        "\n",
        "segmentation_validation_dataloader = DataLoader(segmentation_validation_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "test_set_indices = [9]\n",
        "test_subset_indices = [[0]]\n",
        "\n",
        "test_image_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "test_gt_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),\n",
        "])\n",
        "segmentation_test_dataset = SegSTRONGC(\n",
        "    root_folder = root_folder,\n",
        "    set_indices = test_set_indices,\n",
        "    subset_indices = test_subset_indices,\n",
        "    split = 'test',\n",
        "    domains = ['regular'],\n",
        "    image_transforms = test_image_transforms,\n",
        "    gt_transforms = test_gt_transforms)\n",
        "\n",
        "segmentation_test_dataloader = DataLoader(segmentation_test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "segmentation_test_dataset_blood = SegSTRONGC(\n",
        "    root_folder = root_folder,\n",
        "    set_indices = test_set_indices,\n",
        "    subset_indices = test_subset_indices,\n",
        "    split = 'test',\n",
        "    domains = ['blood'],\n",
        "    image_transforms = test_image_transforms,\n",
        "    gt_transforms = test_gt_transforms)\n",
        "\n",
        "segmentation_test_dataloader_blood = DataLoader(segmentation_test_dataset_blood, batch_size=1, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PWLf2ulZu_v"
      },
      "outputs": [],
      "source": [
        "def show_demo(model, test_dataset_loader, num=10, std=std, mean=mean):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    for demo in test_dataset_loader:\n",
        "        demo_input, demo_target = demo\n",
        "        if use_gpu:\n",
        "           demo_input = demo_input.cuda()\n",
        "        demo_output = model(demo_input)\n",
        "        #denomalize the input image\n",
        "        for i in range(demo_input.shape[0]):\n",
        "            demo_image = demo_input[i].permute(1,2,0).detach().cpu().numpy()\n",
        "            demo_image[:,:,0] = demo_image[:,:,0]*std[0]+mean[0]\n",
        "            demo_image[:,:,1] = demo_image[:,:,1]*std[1]+mean[1]\n",
        "            demo_image[:,:,2] = demo_image[:,:,2]*std[2]+mean[2]\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(demo_image)\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(demo_output[i].detach().cpu().numpy().squeeze()*255)\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(demo_target[i].detach().numpy().squeeze())\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "        if count >= num:\n",
        "          break\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGozZAniD3qJ"
      },
      "source": [
        "### Training vanilla model on vanilla dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i5xNNFBP36Y"
      },
      "outputs": [],
      "source": [
        "segmentation_model = unet(useBN=True)\n",
        "dice_criterion = DICELoss\n",
        "segmentation_optimizer = torch.optim.Adam(segmentation_model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "trainning(segmentation_model, segmentation_trainning_dataloader, segmentation_validation_dataloader,  num_epochs, dice_criterion, segmentation_optimizer, \"final_vanilla_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zAEbKqZjOGZ"
      },
      "outputs": [],
      "source": [
        "segmentation_model.load_state_dict(torch.load(\"final_vanilla_model.pth\"))\n",
        "print(DICE(segmentation_model, segmentation_test_dataloader))\n",
        "show_demo(segmentation_model, segmentation_test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-rQtv8OMT2l"
      },
      "outputs": [],
      "source": [
        "segmentation_model.load_state_dict(torch.load(\"final_vanilla_model.pth\"))\n",
        "print(DICE(segmentation_model, segmentation_test_dataloader_blood))\n",
        "show_demo(segmentation_model, segmentation_test_dataloader_blood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNsWDiDdKYIM"
      },
      "source": [
        "### Do data augmentation for better trainning  \n",
        "\n",
        "Think about what data augmentations you would like to use to help with blood situation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n30IAXVYqfCj"
      },
      "outputs": [],
      "source": [
        "#TODO add transformations in training dataset,\n",
        "# Carefully think about whether the it is suitable for segmentation task\n",
        "train_image_transforms_augmented = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # Convert the image to a PyTorch tensor\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),                      # Resize the image to the desired size\n",
        "    transforms.Normalize(mean=mean, std=std),            # Normalize the image with mean and std\n",
        "])\n",
        "\n",
        "train_gt_transforms_augmented = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST)\n",
        "])\n",
        "segmentation_trainning_dataset_augmented = SegSTRONGC(\n",
        "    root_folder = root_folder,\n",
        "    set_indices = train_set_indices,\n",
        "    subset_indices = train_subset_indices,\n",
        "    split = 'train',\n",
        "    domains = ['regular'],\n",
        "    image_transforms = train_image_transforms_augmented,\n",
        "    gt_transforms = train_gt_transforms_augmented)\n",
        "segmentation_trainning_dataloader_augmented = DataLoader(segmentation_trainning_dataset_augmented, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63IRToRVs1c"
      },
      "source": [
        "Retrain with augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e8ulsdFNZyw"
      },
      "outputs": [],
      "source": [
        "segmentation_model_augmented = unet(useBN=True)\n",
        "dice_criterion = DICELoss\n",
        "segmentation_optimizer_augmented = torch.optim.Adam(segmentation_model_augmented.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "trainning(segmentation_model_augmented, segmentation_trainning_dataloader_augmented, segmentation_validation_dataloader,  num_epochs, dice_criterion, segmentation_optimizer_augmented, \"final_augmented_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM_-ocgSYdD_"
      },
      "outputs": [],
      "source": [
        "segmentation_model_augmented.load_state_dict(torch.load(\"final_augmented_model.pth\"))\n",
        "print(DICE(segmentation_model_augmented, segmentation_test_dataloader))\n",
        "show_demo(segmentation_model_augmented, segmentation_test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhKGYlHUNlDN"
      },
      "outputs": [],
      "source": [
        "segmentation_model_augmented.load_state_dict(torch.load(\"final_augmented_model.pth\"))\n",
        "print(DICE(segmentation_model_augmented, segmentation_test_dataloader_blood))\n",
        "show_demo(segmentation_model_augmented, segmentation_test_dataloader_blood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuNzRlDMkh9M"
      },
      "source": [
        "# Problem 2: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agE7Gbr1lTk3"
      },
      "outputs": [],
      "source": [
        "## Import VGG and FashionMNIST\n",
        "from torchvision.models import vgg16\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "## Specify Batch Size\n",
        "train_batch_size = 32\n",
        "test_batch_size = 32\n",
        "\n",
        "## Specify Image Transforms\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "## Download Datasets\n",
        "train_data = FashionMNIST('./data', transform=img_transform, download=True, train=True)\n",
        "test_data = FashionMNIST('./data', transform=img_transform, download=True, train=False)\n",
        "\n",
        "## Initialize Dataloaders\n",
        "training_dataloader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atSnrneVlaBe"
      },
      "source": [
        "### Model Initialization and Training/Fine-tuning\n",
        "\n",
        "Complete the rest of the assignment in the notebook below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfDZNoO8lbCG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}